{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b634b3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Reference/Code: https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('./PoliceDataFull2021.csv')\n",
    "#print (\"data:\", data)\n",
    "corr = data.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Copied and modified from-\n",
    "# https://stackoverflow.com/questions/27164114/show-confidence-limits-and-prediction-limits-in-scatter-plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupformat(x, ax, plt, title, xlabel, ylabel):\n",
    "    # Figure Modifications --------------------------------------------------------\n",
    "    # Borders\n",
    "    ax.spines[\"top\"].set_color(\"0.5\")\n",
    "    ax.spines[\"bottom\"].set_color(\"0.5\")\n",
    "    ax.spines[\"left\"].set_color(\"0.5\")\n",
    "    ax.spines[\"right\"].set_color(\"0.5\")\n",
    "    ax.get_xaxis().set_tick_params(direction=\"out\")\n",
    "    ax.get_yaxis().set_tick_params(direction=\"out\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.yaxis.tick_left() \n",
    "\n",
    "    # Labels\n",
    "    plt.title(title, fontsize=\"14\", fontweight=\"bold\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(np.min(x) - 1, np.max(x) + 1)\n",
    "\n",
    "    # Custom legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    display = (0, 1)\n",
    "    anyArtist = plt.Line2D((0, 1), (0, 0), color=\"#b9cfe7\")    # create custom artists\n",
    "    legend = plt.legend(\n",
    "        [handle for i, handle in enumerate(handles) if i in display] + [anyArtist],\n",
    "        [label for i, label in enumerate(labels) if i in display] + [\"95% Confidence Limits\"],\n",
    "        loc=9, bbox_to_anchor=(0, -0.21, 1., 0.102), ncol=3, mode=\"expand\"\n",
    "    )  \n",
    "    frame = legend.get_frame().set_edgecolor(\"0.5\")\n",
    "\n",
    "    # Save Figure\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"filename.png\", bbox_extra_artists=(legend,), bbox_inches=\"tight\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poststats(x, y, ax, plt):\n",
    "\n",
    "    #print (\"DEBUG x.shape:\", x.shape, \"y.shape:\", y.shape)\n",
    "    slope, intercept = np.polyfit(np.array(x), np.array(y), 1)  # linear model adjustment\n",
    "\n",
    "    y_model = np.polyval([slope, intercept], x)   # modeling...\n",
    "\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    n = x.size                        # number of samples\n",
    "    m = 2                             # number of parameters\n",
    "    dof = n - m                       # degrees of freedom\n",
    "    t = stats.t.ppf(0.975, dof)       # Students statistic of interval confidence\n",
    "\n",
    "    residual = y - y_model\n",
    "\n",
    "    std_error = (np.sum(residual**2) / dof)**.5   # Standard deviation of the error\n",
    "\n",
    "    # calculating the r2\n",
    "    # https://www.statisticshowto.com/probability-and-statistics/coefficient-of-determination-r-squared/\n",
    "    # Pearson's correlation coefficient\n",
    "    numerator = np.sum((x - x_mean)*(y - y_mean))\n",
    "    denominator = ( np.sum((x - x_mean)**2) * np.sum((y - y_mean)**2) )**.5\n",
    "    correlation_coef = numerator / denominator\n",
    "    r2 = correlation_coef**2\n",
    "\n",
    "    # mean squared error\n",
    "    MSE = 1/n * np.sum( (y - y_model)**2 )\n",
    "\n",
    "    # to plot the adjusted model\n",
    "    x_line = np.linspace(np.min(x), np.max(x), 100)\n",
    "    y_line = np.polyval([slope, intercept], x_line)\n",
    "\n",
    "    # confidence interval\n",
    "    ci = t * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "    # predicting interval\n",
    "    pi = t * std_error * (1 + 1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5  \n",
    "\n",
    "    # rounding and position must be changed for each case and preference\n",
    "    a = str(np.round(intercept))\n",
    "    b = str(np.round(slope,2))\n",
    "    r2s = str(np.round(r2,2))\n",
    "    MSEs = str(np.round(MSE))\n",
    "\n",
    "    ax.text(min(x), max(y), 'y = ' + a + ' + ' + b + ' x' + '\\n' + '$r^2$ = ' + r2s + '     MSE = ' + MSEs)\n",
    "    #plt.legend(loc='upper right', bbox_to_anchor=(1, .25), fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ci_manual(t, s_err, n, x, x2, y, y2, title, xlabel, ylabel, ax=None):\n",
    "    \"\"\"Return an axes of confidence bands using a simple approach.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    .. math:: \\left| \\: \\hat{\\mu}_{y|x0} - \\mu_{y|x0} \\: \\right| \\; \\leq \\; T_{n-2}^{.975} \\; \\hat{\\sigma} \\; \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\bar{x})^2}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}}\n",
    "    .. math:: \\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n{\\frac{(y_i-\\hat{y})^2}{n-2}}}\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Duarte.  \"Curve fitting,\" Jupyter Notebook.\n",
    "       http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/CurveFitting.ipynb\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ci = t * s_err * np.sqrt(1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "    ax.fill_between(x2, y2 + ci, y2 - ci, color=\"#b9cfe7\", edgecolor=\"\")\n",
    "    setupformat(x, ax, plt, title, xlabel, ylabel)\n",
    "    poststats(x, y,ax,plt)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095db2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computations ----------------------------------------------------------------    \n",
    "\n",
    "def plot(x, y, title, xlabel, ylabel):\n",
    "    # Modeling with Numpy\n",
    "    def equation(a, b):\n",
    "        \"\"\"Return a 1D polynomial.\"\"\"\n",
    "        return np.polyval(a, b) \n",
    "\n",
    "    p, cov = np.polyfit(np.array(x), np.array(y), 1, cov=True)                     # parameters and covariance from of the fit of 1-D polynom.\n",
    "    y_model = equation(p, x)                                   # model using the fit parameters; NOTE: parameters here are coefficients\n",
    "\n",
    "    # Statistics\n",
    "    n = x.size                                                 # number of observations\n",
    "    m = p.size                                                 # number of parameters\n",
    "    dof = n - m                                                # degrees of freedom\n",
    "    t = stats.t.ppf(0.975, n - m)                              # used for CI and PI bands\n",
    "\n",
    "    # Estimates of Error in Data/Model\n",
    "    resid = y - y_model                           \n",
    "    chi2 = np.sum((resid / y_model)**2)                        # chi-squared; estimates error in data\n",
    "    chi2_red = chi2 / dof                                      # reduced chi-squared; measures goodness of fit\n",
    "    s_err = np.sqrt(np.sum(resid**2) / dof)                    # standard deviation of the error\n",
    "\n",
    "    # Plotting --------------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Data\n",
    "    ax.plot(\n",
    "        x, y, \"o\", color=\"#b9cfe7\", markersize=8, \n",
    "        markeredgewidth=1, markeredgecolor=\"b\", markerfacecolor=\"None\"\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    ax.plot(x, y_model, \"-\", color=\"0.1\", linewidth=1.5, alpha=0.5, label=\"Fit\")  \n",
    "\n",
    "    x2 = np.linspace(np.min(x), np.max(x), 100)\n",
    "    y2 = equation(p, x2)\n",
    "\n",
    "    # Prediction Interval\n",
    "    pi = t * s_err * np.sqrt(1 + 1/n + (x2 - np.mean(x))**2 / np.sum((x - np.mean(x))**2))   \n",
    "    ax.fill_between(x2, y2 + pi, y2 - pi, color=\"None\", linestyle=\"--\")\n",
    "    ax.plot(x2, y2 - pi, \"--\", color=\"0.5\", label=\"95% Prediction Limits\")\n",
    "    ax.plot(x2, y2 + pi, \"--\", color=\"0.5\")\n",
    "\n",
    "    # Confidence Interval (select one)\n",
    "    plot_ci_manual(t, s_err, n, x, x2, y, y2, title, xlabel, ylabel, ax=ax)\n",
    "    #plot_ci_bootstrap(x, y, resid, ax=ax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually plotting real police data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotcombinations(data):\n",
    "    columns = data.columns\n",
    "    tot = 0\n",
    "    for i, ylabel in enumerate(columns):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            #Hacky, but put x-axis as later values so gender and left force only appears on x-axis\n",
    "            xlabel = columns[j]\n",
    "            title = \"Plotting \" + ylabel + \" vs \" + xlabel\n",
    "            plot(np.ravel(data[xlabel]), np.ravel(data[ylabel]), title, xlabel, ylabel)\n",
    "            tot += 1\n",
    "    print (\"Total \", tot, \"combinations\")\n",
    "plotcombinations(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dbb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot a selected piece of data\n",
    "def plotone(data, xlabel, ylabel):\n",
    "    columns = data.columns\n",
    "    title = \"Plotting \" + ylabel + \" vs \" + xlabel\n",
    "    plot(np.ravel(data[xlabel]), np.ravel(data[ylabel]), title, xlabel, ylabel)\n",
    "#plotone(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
